{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"provenance":[],"authorship_tag":"ABX9TyP9upSQX2OTCk7POhR2sffh"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"},"gpuClass":"standard"},"cells":[{"cell_type":"code","source":["!pip install -q kaggle"],"metadata":{"id":"AoBssZQuukUi","executionInfo":{"status":"ok","timestamp":1669599787200,"user_tz":-330,"elapsed":7016,"user":{"displayName":"Utkarsh Belkhede","userId":"15069854910285996129"}}},"execution_count":1,"outputs":[]},{"cell_type":"code","source":["from google.colab import files\n","files.upload()"],"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":91},"id":"h6kGgKyeuyLf","executionInfo":{"status":"ok","timestamp":1669596942830,"user_tz":-330,"elapsed":6995,"user":{"displayName":"Utkarsh Belkhede","userId":"15069854910285996129"}},"outputId":"d4f577e5-0e6a-4e77-d98a-ae62719baf17"},"execution_count":24,"outputs":[{"output_type":"display_data","data":{"text/plain":["<IPython.core.display.HTML object>"],"text/html":["\n","     <input type=\"file\" id=\"files-aa4f49e9-2b5b-4754-9f66-565a1395c032\" name=\"files[]\" multiple disabled\n","        style=\"border:none\" />\n","     <output id=\"result-aa4f49e9-2b5b-4754-9f66-565a1395c032\">\n","      Upload widget is only available when the cell has been executed in the\n","      current browser session. Please rerun this cell to enable.\n","      </output>\n","      <script>// Copyright 2017 Google LLC\n","//\n","// Licensed under the Apache License, Version 2.0 (the \"License\");\n","// you may not use this file except in compliance with the License.\n","// You may obtain a copy of the License at\n","//\n","//      http://www.apache.org/licenses/LICENSE-2.0\n","//\n","// Unless required by applicable law or agreed to in writing, software\n","// distributed under the License is distributed on an \"AS IS\" BASIS,\n","// WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n","// See the License for the specific language governing permissions and\n","// limitations under the License.\n","\n","/**\n"," * @fileoverview Helpers for google.colab Python module.\n"," */\n","(function(scope) {\n","function span(text, styleAttributes = {}) {\n","  const element = document.createElement('span');\n","  element.textContent = text;\n","  for (const key of Object.keys(styleAttributes)) {\n","    element.style[key] = styleAttributes[key];\n","  }\n","  return element;\n","}\n","\n","// Max number of bytes which will be uploaded at a time.\n","const MAX_PAYLOAD_SIZE = 100 * 1024;\n","\n","function _uploadFiles(inputId, outputId) {\n","  const steps = uploadFilesStep(inputId, outputId);\n","  const outputElement = document.getElementById(outputId);\n","  // Cache steps on the outputElement to make it available for the next call\n","  // to uploadFilesContinue from Python.\n","  outputElement.steps = steps;\n","\n","  return _uploadFilesContinue(outputId);\n","}\n","\n","// This is roughly an async generator (not supported in the browser yet),\n","// where there are multiple asynchronous steps and the Python side is going\n","// to poll for completion of each step.\n","// This uses a Promise to block the python side on completion of each step,\n","// then passes the result of the previous step as the input to the next step.\n","function _uploadFilesContinue(outputId) {\n","  const outputElement = document.getElementById(outputId);\n","  const steps = outputElement.steps;\n","\n","  const next = steps.next(outputElement.lastPromiseValue);\n","  return Promise.resolve(next.value.promise).then((value) => {\n","    // Cache the last promise value to make it available to the next\n","    // step of the generator.\n","    outputElement.lastPromiseValue = value;\n","    return next.value.response;\n","  });\n","}\n","\n","/**\n"," * Generator function which is called between each async step of the upload\n"," * process.\n"," * @param {string} inputId Element ID of the input file picker element.\n"," * @param {string} outputId Element ID of the output display.\n"," * @return {!Iterable<!Object>} Iterable of next steps.\n"," */\n","function* uploadFilesStep(inputId, outputId) {\n","  const inputElement = document.getElementById(inputId);\n","  inputElement.disabled = false;\n","\n","  const outputElement = document.getElementById(outputId);\n","  outputElement.innerHTML = '';\n","\n","  const pickedPromise = new Promise((resolve) => {\n","    inputElement.addEventListener('change', (e) => {\n","      resolve(e.target.files);\n","    });\n","  });\n","\n","  const cancel = document.createElement('button');\n","  inputElement.parentElement.appendChild(cancel);\n","  cancel.textContent = 'Cancel upload';\n","  const cancelPromise = new Promise((resolve) => {\n","    cancel.onclick = () => {\n","      resolve(null);\n","    };\n","  });\n","\n","  // Wait for the user to pick the files.\n","  const files = yield {\n","    promise: Promise.race([pickedPromise, cancelPromise]),\n","    response: {\n","      action: 'starting',\n","    }\n","  };\n","\n","  cancel.remove();\n","\n","  // Disable the input element since further picks are not allowed.\n","  inputElement.disabled = true;\n","\n","  if (!files) {\n","    return {\n","      response: {\n","        action: 'complete',\n","      }\n","    };\n","  }\n","\n","  for (const file of files) {\n","    const li = document.createElement('li');\n","    li.append(span(file.name, {fontWeight: 'bold'}));\n","    li.append(span(\n","        `(${file.type || 'n/a'}) - ${file.size} bytes, ` +\n","        `last modified: ${\n","            file.lastModifiedDate ? file.lastModifiedDate.toLocaleDateString() :\n","                                    'n/a'} - `));\n","    const percent = span('0% done');\n","    li.appendChild(percent);\n","\n","    outputElement.appendChild(li);\n","\n","    const fileDataPromise = new Promise((resolve) => {\n","      const reader = new FileReader();\n","      reader.onload = (e) => {\n","        resolve(e.target.result);\n","      };\n","      reader.readAsArrayBuffer(file);\n","    });\n","    // Wait for the data to be ready.\n","    let fileData = yield {\n","      promise: fileDataPromise,\n","      response: {\n","        action: 'continue',\n","      }\n","    };\n","\n","    // Use a chunked sending to avoid message size limits. See b/62115660.\n","    let position = 0;\n","    do {\n","      const length = Math.min(fileData.byteLength - position, MAX_PAYLOAD_SIZE);\n","      const chunk = new Uint8Array(fileData, position, length);\n","      position += length;\n","\n","      const base64 = btoa(String.fromCharCode.apply(null, chunk));\n","      yield {\n","        response: {\n","          action: 'append',\n","          file: file.name,\n","          data: base64,\n","        },\n","      };\n","\n","      let percentDone = fileData.byteLength === 0 ?\n","          100 :\n","          Math.round((position / fileData.byteLength) * 100);\n","      percent.textContent = `${percentDone}% done`;\n","\n","    } while (position < fileData.byteLength);\n","  }\n","\n","  // All done.\n","  yield {\n","    response: {\n","      action: 'complete',\n","    }\n","  };\n","}\n","\n","scope.google = scope.google || {};\n","scope.google.colab = scope.google.colab || {};\n","scope.google.colab._files = {\n","  _uploadFiles,\n","  _uploadFilesContinue,\n","};\n","})(self);\n","</script> "]},"metadata":{}},{"output_type":"stream","name":"stdout","text":["Saving kaggle (1).json to kaggle (1).json\n"]},{"output_type":"execute_result","data":{"text/plain":["{'kaggle (1).json': b'{\"username\":\"utkarshbelkhede\",\"key\":\"f18d8db755a065a7225d2c4a976097b5\"}'}"]},"metadata":{},"execution_count":24}]},{"cell_type":"code","source":["import kaggle"],"metadata":{"id":"A08WKparuWU8"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["!mkdir ~/.kaggle"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"lziWqQJQ5bpu","executionInfo":{"status":"ok","timestamp":1669599722720,"user_tz":-330,"elapsed":26,"user":{"displayName":"Utkarsh Belkhede","userId":"15069854910285996129"}},"outputId":"3e8801da-aa6e-44db-8c8c-f6956a377135"},"execution_count":30,"outputs":[{"output_type":"stream","name":"stdout","text":["mkdir: cannot create directory ‘/root/.kaggle’: File exists\n"]}]},{"cell_type":"code","source":["!chmod 600 ~/.kaggle/kaggle.json"],"metadata":{"id":"Um7zeFbQpApm","executionInfo":{"status":"ok","timestamp":1669599939748,"user_tz":-330,"elapsed":8,"user":{"displayName":"Utkarsh Belkhede","userId":"15069854910285996129"}}},"execution_count":3,"outputs":[]},{"cell_type":"code","source":["!kaggle datasets download -d gutomitai/rbm-softmax-mnist-digit-classifier"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"ie5d_kniqOEz","executionInfo":{"status":"ok","timestamp":1669599947831,"user_tz":-330,"elapsed":1891,"user":{"displayName":"Utkarsh Belkhede","userId":"15069854910285996129"}},"outputId":"d233c1ad-3812-49a8-cc7d-7515768e6cbb"},"execution_count":4,"outputs":[{"output_type":"stream","name":"stdout","text":["403 - Forbidden\n"]}]},{"cell_type":"code","source":["!kaggle kernels output gutomitai/rbm-softmax-mnist-digit-classifier -p /datasets"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"7KoU_iS2pS3s","executionInfo":{"status":"ok","timestamp":1669596638356,"user_tz":-330,"elapsed":1449,"user":{"displayName":"Utkarsh Belkhede","userId":"15069854910285996129"}},"outputId":"14e5e9c8-2921-4ea7-be06-5a029ede9055"},"execution_count":22,"outputs":[{"output_type":"stream","name":"stdout","text":["Output file downloaded to /datasets/digit_classificaton_model.h5\n","Output file downloaded to /datasets/output\n","Kernel log downloaded to /datasets/rbm-softmax-mnist-digit-classifier.log \n"]}]},{"cell_type":"code","source":["import numpy as np # linear algebra\n","\n","import pandas as pd # data processing, CSV file"],"metadata":{"id":"zBEYamr9mnM8","executionInfo":{"status":"ok","timestamp":1669595011922,"user_tz":-330,"elapsed":11,"user":{"displayName":"Utkarsh Belkhede","userId":"15069854910285996129"}}},"execution_count":5,"outputs":[]},{"cell_type":"code","source":["import argparse\n","import time\n","\n","from keras.models import Model, load_model\n","from keras.layers import Input, Dense, Lambda\n","from keras import optimizers\n","from keras import backend as K\n","from keras.layers import Layer, Input\n","from keras import initializers"],"metadata":{"id":"D4RktSJjm6L5","executionInfo":{"status":"ok","timestamp":1669595184571,"user_tz":-330,"elapsed":9,"user":{"displayName":"Utkarsh Belkhede","userId":"15069854910285996129"}}},"execution_count":8,"outputs":[]},{"cell_type":"code","execution_count":9,"metadata":{"id":"HhqQztoMmMOH","executionInfo":{"status":"ok","timestamp":1669595188084,"user_tz":-330,"elapsed":483,"user":{"displayName":"Utkarsh Belkhede","userId":"15069854910285996129"}}},"outputs":[],"source":["class RBM(Layer):\n","    \"\"\"Restricted Boltzmann Machine based on Keras.\"\"\"\n","    def __init__(self, hps, output_dim, name=None, **kwargs):\n","        self.hps = hps\n","        self.output_dim = output_dim\n","        self.name = name\n","        super(RBM, self).__init__(**kwargs)\n","    \n","    def build(self, input_shape):\n","        self.rbm_weight = self.add_weight(name='rbm_weight'\n","                                 , shape=(input_shape[1], self.output_dim)\n","                                 , initializer='uniform' # Which initializer is optimal?\n","                                 , trainable=True)\n","\n","        self.hidden_bias = self.add_weight(name='rbm_hidden_bias'\n","                                           , shape=(self.output_dim, )\n","                                           , initializer='uniform'\n","                                           , trainable=True)\n","        self.visible_bias = K.variable(initializers.get('uniform')((input_shape[1], ))\n","                            , dtype=K.floatx()\n","                            , name='rbm_visible_bias')\n","        \n","        # Make symbolic computation objects.\n","        # Transform visible units.\n","        self.input_visible = K.placeholder(shape=(None, input_shape[1]), name='input_visible')\n","        self.transform = K.sigmoid(K.dot(self.input_visible, self.rbm_weight) + self.hidden_bias)\n","        self.transform_func = K.function([self.input_visible], [self.transform])\n","  \n","        # Transform hidden units.      \n","        self.input_hidden = K.placeholder(shape=(None, self.output_dim), name='input_hidden')\n","        self.inv_transform = K.sigmoid(K.dot(self.input_hidden, K.transpose(self.rbm_weight)) + self.visible_bias)\n","        self.inv_transform_func = K.function([self.input_hidden], [self.inv_transform])\n","        \n","        # Calculate free energy.\n","        self.free_energy = -1 * (K.squeeze(K.dot(self.input_visible, K.expand_dims(self.visible_bias, axis=-1)), -1) +\\\n","                                K.sum(K.log(1 + K.exp(K.dot(self.input_visible, self.rbm_weight) +\\\n","                                                self.hidden_bias)), axis=-1))\n","        self.free_energy_func = K.function([self.input_visible], [self.free_energy])\n","\n","        super(RBM, self).build(input_shape)\n","        \n","    def call(self, x):\n","        return K.sigmoid(K.dot(x, self.rbm_weight) + self.hidden_bias) # Float type?\n","    \n","    def transform(self, v):\n","        return self.transform_func(v)\n","    \n","    def inv_transform(self, h):\n","        return self.inv_transform_func(h)\n","        \n","    def compute_output_shape(self, input_shape):\n","        return (input_shape[0], self.output_dim)\n","    \n","    def cal_free_energy(self, v):\n","        return self.free_energy_func(v)\n","    \n","    def fit(self, V, verbose=1):\n","        \"\"\"Train RBM with the data V.\n","        \n","        Parameters\n","        ----------\n","        V : 2d numpy array\n","            Visible data (batch size x input_dim).\n","        verbose : integer\n","            Verbose mode (default, 1).\n","        \"\"\"\n","        num_step = V.shape[0] // self.hps['batch_size'] \\\n","            if V.shape[0] % self.hps['batch_size'] == 0 else V.shape[0] // self.hps['batch_size'] + 1 # Exception processing?\n","             \n","        for k in range(self.hps['epochs']):\n","            if verbose == 1:\n","                print(k + 1, '/', self.hps['epochs'], ' epochs')\n","\n","            # Contrastive divergence.\n","            v_pos = self.input_visible\n","            h_pos = self.transform\n","            v_neg = K.cast(K.less(K.random_uniform(shape=(self.hps['batch_size'], V.shape[1]))\n","                    , K.sigmoid(K.dot(h_pos, K.transpose(self.rbm_weight)) + self.visible_bias))\n","                    , dtype=np.float32)\n","            h_neg = K.sigmoid(K.dot(v_neg, self.rbm_weight) + self.hidden_bias)\n","            update = K.transpose(K.transpose(K.dot(K.transpose(v_pos), h_pos)) \\\n","                                 - K.dot(K.transpose(h_neg), v_neg))\n","            self.rbm_weight_update_func = K.function([self.input_visible]\n","                                            , [K.update_add(self.rbm_weight, self.hps['lr'] * update)])\n","            self.hidden_bias_update_func = K.function([self.input_visible]\n","                                            , [K.update_add(self.hidden_bias, self.hps['lr'] \\\n","                                            * (K.sum(h_pos, axis=0) - K.sum(h_neg, axis=0)))])\n","            self.visible_bias_update_func = K.function([self.input_visible]\n","                                            , [K.update_add(self.visible_bias, self.hps['lr'] \\\n","                                            * (K.sum(v_pos, axis=0) - K.sum(v_neg, axis=0)))])\n","            \n","            # Create the fist visible nodes sampling object.\n","            self.sample_first_visible = K.function([self.input_visible]\n","                                                , [v_neg])       \n","            for i in range(num_step):\n","                if i == (num_step - 1):\n","                    # Contrastive divergence.\n","                    v_pos = self.input_visible\n","                    h_pos = self.transform\n","                    v_neg = K.cast(K.less(K.random_uniform(shape=(V.shape[0] - int(i*self.hps['batch_size'])\n","                                   , V.shape[1])) #?\n","                                   , K.sigmoid(K.dot(h_pos, K.transpose(self.rbm_weight)) \\\n","                                   + self.visible_bias)), dtype=np.float32)\n","                    h_neg = K.sigmoid(K.dot(v_neg, self.rbm_weight) + self.hidden_bias)\n","                    update = K.transpose(K.transpose(K.dot(K.transpose(v_pos), h_pos)) \\\n","                                         - K.dot(K.transpose(h_neg), v_neg))\n","                    self.rbm_weight_update_func = K.function([self.input_visible]\n","                                                , [K.update_add(self.rbm_weight, self.hps['lr'] * update)])\n","                    self.hidden_bias_update_func = K.function([self.input_visible]\n","                                                 , [K.update_add(self.hidden_bias, self.hps['lr'] \\\n","                                                 * (K.sum(h_pos, axis=0) - K.sum(h_neg, axis=0)))])\n","                    self.visible_bias_update_func = K.function([self.input_visible]\n","                                                  , [K.update_add(self.visible_bias, self.hps['lr'] \\\n","                                                  * (K.sum(v_pos, axis=0) - K.sum(v_neg, axis=0)))])\n","\n","                    # Create the fist visible nodes sampling object.\n","                    self.sample_first_visible = K.function([self.input_visible]\n","                                                , [v_neg])\n","\n","                    V_batch = [V[int(i*self.hps['batch_size']):V.shape[0]]]\n","                    \n","                    # Train.\n","                    self.rbm_weight_update_func(V_batch)\n","                    self.hidden_bias_update_func(V_batch)\n","                    self.visible_bias_update_func(V_batch)\n","                else:\n","                    V_batch = [V[int(i*self.hps['batch_size']):int((i+1)*self.hps['batch_size'])]]\n","                    \n","                    # Train.\n","                    self.rbm_weight_update_func(V_batch)\n","                    self.hidden_bias_update_func(V_batch)\n","                    self.visible_bias_update_func(V_batch)\n","            \n","                # Calculate a training score by each step.\n","                # Free energy of the input visible nodes.\n","                fe = self.cal_free_energy(V_batch)\n","                \n","                # Free energy of the first sampled visible nodes.\n","                V_p_batch = self.sample_first_visible(V_batch)\n","                fe_p = self.cal_free_energy(V_p_batch)\n","                \n","                score = np.mean(np.abs(fe[0] - fe_p[0])) # Scale?\n","                print('{0:d}/{1:d}, score: {2:f}'.format(i + 1, num_step, score))\n","\n","# Constants.\n","DEBUG = True\n","MULTI_GPU = False\n","NUM_GPUS = 4"]},{"cell_type":"code","source":["class MNISTClassifier(object):\n","    \"\"\"MNIST digit classifier using the RBM + Softmax model.\"\"\"\n","    # Constants.\n","    MODEL_PATH = 'digit_classificaton_model.h5'\n","    IMAGE_SIZE = 784\n","    \n","    def __init__(self, hps, nn_arch_info, model_loading=False):\n","        self.hps = hps\n","        self.nn_arch_info = nn_arch_info\n","\n","        if model_loading: \n","            if MULTI_GPU:\n","                self.digit_classificaton_model = load_model(self.MODEL_PATH, custom_objects={'RBM': RBM}) # Custom layer loading problem?\n","                self.rbm = self.digit_classificaton_model.get_layer('rbm')\n","                \n","                self.digit_classificaton_parallel_model = multi_gpu_model(self.model, gpus = NUM_GPUS)\n","                opt = optimizers.Adam(lr=self.hps['lr']\n","                                        , beta_1=self.hps['beta_1']\n","                                        , beta_2=self.hps['beta_2']\n","                                        , decay=self.hps['decay']) \n","                self.digit_classificaton_parallel_model.compile(optimizer=opt, loss='mse') \n","            else:\n","                self.digit_classificaton_model = load_model(self.MODEL_PATH, custom_objects={'RBM': RBM})\n","                self.rbm = self.digit_classificaton_model.get_layer('rbm')\n","        else:        \n","            # Design the model.\n","            input_image = Input(shape=(self.IMAGE_SIZE,))\n","            x = Lambda(lambda x: x/255)(input_image)\n","            \n","            # RBM layer.\n","            self.rbm = RBM(self.hps['rbm_hps'], self.nn_arch_info['output_dim'], name='rbm')\n","            x = self.rbm(x) #?\n","            \n","            # Softmax layer.\n","            output = Dense(10, activation='softmax')(x)\n","            \n","            # Create a model.\n","            self.digit_classificaton_model = Model(inputs=[input_image], outputs=[output])\n","            \n","            opt = optimizers.Adam(lr=self.hps['lr']\n","                                    , beta_1=self.hps['beta_1']\n","                                    , beta_2=self.hps['beta_2']\n","                                    , decay=self.hps['decay'])\n","            \n","            self.digit_classificaton_model.compile(optimizer=opt, loss='categorical_crossentropy')\n","            self.digit_classificaton_model.summary() \n","\n","    def train(self):\n","        \"\"\"Train.\"\"\"\n","        # Load training data.\n","        V, gt = self._load_training_data()\n","        \n","        # Semi-supervised learning.\n","        # Unsupervised learning.\n","        # RBM training.\n","        print('Train the RBM model.')\n","        self.rbm.fit(V)\n","        \n","        # Supervised learning.\n","        print('Train the NN model.')\n","        if MULTI_GPU:\n","            self.digit_classificaton_parallel_model.fit(V\n","                                           , gt\n","                                           , batch_size=self.hps['batch_size']\n","                                           , epochs=self.hps['epochs']\n","                                           , verbose=1)        \n","        else:\n","            self.digit_classificaton_model.fit(V\n","                                           , gt\n","                                           , batch_size=self.hps['batch_size']\n","                                           , epochs=self.hps['epochs']\n","                                           , verbose=1)\n","\n","        print('Save the model.')            \n","        self.digit_classificaton_model.save(self.MODEL_PATH)\n","    \n","    def _load_training_data(self):\n","        \"\"\"Load training data.\"\"\"\n","        train_df = pd.read_csv('../input/train.csv')\n","        V = []\n","        gt = []\n","        \n","        for i in range(train_df.shape[0]):\n","            V.append(train_df.iloc[i, 1:].values/255)\n","            t_gt = np.zeros(shape=(10,))\n","            t_gt[train_df.iloc[i,0]] = 1.\n","            gt.append(t_gt)\n","        \n","        V = np.asarray(V, dtype=np.float32)\n","        gt = np.asarray(gt, dtype=np.float32)\n","        \n","        return V, gt\n","    \n","    def test(self):\n","        \"\"\"Test.\"\"\"\n","        # Load test data.\n","        V = self._load_test_data()\n","        \n","        # Predict digits.\n","        res = self.digit_classificaton_model.predict(V\n","                                                     , verbose=1)\n","        \n","        # Record results into a file.\n","        with open('output', 'w') as f:\n","            f.write('ImageId,Label\\n')\n","            \n","            for i, v in enumerate(res):\n","                f.write(str(i + 1) + ',' + str(np.argmax(v)) + '\\n') \n","        \n","    def _load_test_data(self):\n","        \"\"\"Load test data.\"\"\"\n","        test_df = pd.read_csv('../input/test.csv')\n","        V = []\n","        \n","        for i in range(test_df.shape[0]):\n","            V.append(test_df.iloc[i, :].values/255)\n","        \n","        V = np.asarray(V, dtype=np.float32)\n","        \n","        return V "],"metadata":{"id":"sJJ_Vb4Vm01r","executionInfo":{"status":"ok","timestamp":1669595228128,"user_tz":-330,"elapsed":13,"user":{"displayName":"Utkarsh Belkhede","userId":"15069854910285996129"}}},"execution_count":10,"outputs":[]},{"cell_type":"code","source":["def main():\n","    \"\"\"Main.\"\"\"\n","    hps = {}\n","    nn_arch_info = {}\n","\n","    # Get arguments.      \n","    nn_arch_info['output_dim'] = 128   \n","        \n","    hps['lr'] = 0.001\n","    hps['beta_1'] = 0.99\n","    hps['beta_2'] = 0.99\n","    hps['decay'] = 0.0\n","    hps['batch_size'] = 128\n","    hps['epochs'] = 1 # 100: Saturation #epochs\n","        \n","    rbm_hps = {}\n","    rbm_hps['lr'] = 0.001\n","    rbm_hps['batch_size'] = 128\n","    rbm_hps['epochs'] = 1 # 100: Saturation #epochs\n","    hps['rbm_hps'] = rbm_hps        \n","        \n","    model_loading = False        \n","        \n","    # Train.\n","    mc = MNISTClassifier(hps, nn_arch_info, model_loading)\n","        \n","    ts = time.time()\n","    mc.train()\n","    mc.test()\n","    te = time.time()\n","        \n","    print('Elasped time: {0:f}s'.format(te-ts))"],"metadata":{"id":"lt7Hapm1oWSS"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["main()"],"metadata":{"id":"o5pcU8Q0om8b"},"execution_count":null,"outputs":[]}]}